{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from pykrx import stock\r\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Flatten, Dropout, BatchNormalization, Reshape, LeakyReLU\r\n",
    "from tensorflow.keras.models import Model, Sequential\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
    "import tensorflow as tf\r\n",
    "from datetime import datetime, timedelta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "df = stock.get_market_ohlcv_by_date(\"19990106\", \"20210714\", \"000660\")\r\n",
    "volume_df = stock.get_market_trading_volume_by_date(\"19990106\", \"20210714\", \"000660\")\r\n",
    "del volume_df['기타법인']\r\n",
    "del volume_df['전체']\r\n",
    "df = df.join(volume_df)\r\n",
    "df = df.dropna()\r\n",
    "print(df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                시가      고가      저가      종가      거래량       기관합계         개인  \\\n",
      "날짜                                                                          \n",
      "1999-01-06  364223  382090  354602  354601  1048060    28270.0   841250.0   \n",
      "1999-01-07  407517  407517  384839  407517  3325700 -1242610.0  2322640.0   \n",
      "1999-01-08  399958  399958  362161  369720  1105840   -66980.0   336250.0   \n",
      "1999-01-11  361474  389650  344981  364909  1321090   -53250.0   419310.0   \n",
      "1999-01-12  364910  382090  360099  364222   777710   -56680.0   205950.0   \n",
      "...            ...     ...     ...     ...      ...        ...        ...   \n",
      "2021-07-08  123500  123500  121000  121500  3165552  -172724.0  1062210.0   \n",
      "2021-07-09  120500  120500  118000  119500  4823577  -439187.0  1576301.0   \n",
      "2021-07-12  121000  122000  119500  120000  2477201   -65203.0   174530.0   \n",
      "2021-07-13  121000  123500  121000  123000  2879072   116372.0 -1093033.0   \n",
      "2021-07-14  122500  124000  121500  123500  2443087  -106894.0  -393989.0   \n",
      "\n",
      "                외국인합계  \n",
      "날짜                     \n",
      "1999-01-06  -869520.0  \n",
      "1999-01-07 -1080030.0  \n",
      "1999-01-08  -269270.0  \n",
      "1999-01-11  -366060.0  \n",
      "1999-01-12  -149270.0  \n",
      "...               ...  \n",
      "2021-07-08  -871557.0  \n",
      "2021-07-09 -1153724.0  \n",
      "2021-07-12  -198302.0  \n",
      "2021-07-13  1068500.0  \n",
      "2021-07-14   522022.0  \n",
      "\n",
      "[5552 rows x 8 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "df.to_csv('Sample_2.csv', encoding = \"utf-8-sig\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "test_array = np.zeros(shape = (8, 5552))\r\n",
    "for i in range(8):\r\n",
    "    tmp = []\r\n",
    "    for j in range(len(df.index)):\r\n",
    "        tmp.append(df.iloc[j][i])\r\n",
    "    max_tmp = max(tmp)\r\n",
    "    min_tmp = min(tmp)\r\n",
    "    print(max_tmp, min_tmp)\r\n",
    "    for j in range(len(tmp)):\r\n",
    "        tmp[j] = (tmp[j] - min_tmp)/(max_tmp - min_tmp)\r\n",
    "    arr_tmp = np.array(tmp)\r\n",
    "    test_array[i] = arr_tmp\r\n",
    "    #print(norm_arr.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "754502.0 2650.0\n",
      "770480.0 2944.0\n",
      "713670.0 2454.0\n",
      "718996.0 2650.0\n",
      "1832794266.0 494550.0\n",
      "9929240.0 -208355414.0\n",
      "207103064.0 -27931553.0\n",
      "30005613.0 -38321590.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "fin_array = test_array.T\r\n",
    "fin_array = fin_array.reshape(-1, 8, 8, 1)\r\n",
    "print(fin_array.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(694, 8, 8, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "encoder_input = tf.keras.Input(shape=(8, 8, 1))\r\n",
    "\r\n",
    "x = Conv2D(32, 2, padding='same')(encoder_input)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = LeakyReLU()(x)\r\n",
    "\r\n",
    "x = Conv2D(64, 2, strides=2, padding='same')(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = LeakyReLU()(x)\r\n",
    "\r\n",
    "x = Conv2D(64, 2, strides=2, padding='same')(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = LeakyReLU()(x)\r\n",
    "\r\n",
    "x = Conv2D(64, 2, padding='same')(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = LeakyReLU()(x)\r\n",
    "\r\n",
    "x = Flatten()(x)\r\n",
    "\r\n",
    "encoder_output = Dense(2)(x)\r\n",
    "\r\n",
    "encoder = Model(encoder_input, encoder_output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "decoder_input = tf.keras.Input(shape=(2, ))\r\n",
    "\r\n",
    "x = Dense(2*2*64)(decoder_input)\r\n",
    "x = Reshape((2, 2, 64))(x)\r\n",
    "\r\n",
    "x = Conv2DTranspose(64, 2, strides=1, padding='same')(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = LeakyReLU()(x)\r\n",
    "\r\n",
    "x = Conv2DTranspose(64, 2, strides=1, padding='same')(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = LeakyReLU()(x)\r\n",
    "\r\n",
    "x = Conv2DTranspose(64, 2, strides=2, padding='same')(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = LeakyReLU()(x)\r\n",
    "\r\n",
    "x = Conv2DTranspose(32, 2, strides=2, padding='same')(x)\r\n",
    "x = BatchNormalization()(x)\r\n",
    "x = LeakyReLU()(x)\r\n",
    "\r\n",
    "decoder_output = Conv2DTranspose(1, 2, strides=1, padding='same', activation='tanh')(x)\r\n",
    "\r\n",
    "decoder = Model(decoder_input, decoder_output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "LEARNING_RATE = 0.0005\r\n",
    "BATCH_SIZE = 32\r\n",
    "\r\n",
    "encoder_in = tf.keras.Input(shape=(8, 8, 1))\r\n",
    "x = encoder(encoder_in)\r\n",
    "decoder_out = decoder(x)\r\n",
    "\r\n",
    "auto_encoder = Model(encoder_in, decoder_out)\r\n",
    "auto_encoder.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE), loss=tf.keras.losses.MeanSquaredError())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "checkpoint_path = 'tmp/result_2.ckpt'\r\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, save_weights_only=True, monitor='loss', verbose=1)\r\n",
    "\r\n",
    "auto_encoder.fit(fin_array, fin_array, batch_size=BATCH_SIZE, epochs=30, callbacks=[checkpoint], )\r\n",
    "auto_encoder.load_weights(checkpoint_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 5.6235e-04\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.00056, saving model to tmp\\result_2.ckpt\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 5.2115e-04\n",
      "\n",
      "Epoch 00002: loss improved from 0.00056 to 0.00052, saving model to tmp\\result_2.ckpt\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 5.2597e-04\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00052\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 5.4947e-04\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00052\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 4.8050e-04\n",
      "\n",
      "Epoch 00005: loss improved from 0.00052 to 0.00048, saving model to tmp\\result_2.ckpt\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 4.6099e-04\n",
      "\n",
      "Epoch 00006: loss improved from 0.00048 to 0.00046, saving model to tmp\\result_2.ckpt\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 4.7841e-04\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00046\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 4.6064e-04\n",
      "\n",
      "Epoch 00008: loss improved from 0.00046 to 0.00046, saving model to tmp\\result_2.ckpt\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 4.8370e-04\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00046\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 5.3314e-04\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00046\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 5.9464e-04\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00046\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 5.3883e-04\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00046\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 4.7542e-04\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00046\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 4.7832e-04\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00046\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 4.7850e-04\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00046\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 4.6074e-04\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00046\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 5.0591e-04\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00046\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 5.3156e-04\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00046\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 4.5499e-04\n",
      "\n",
      "Epoch 00019: loss improved from 0.00046 to 0.00045, saving model to tmp\\result_2.ckpt\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 4.3406e-04\n",
      "\n",
      "Epoch 00020: loss improved from 0.00045 to 0.00043, saving model to tmp\\result_2.ckpt\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 4.3500e-04\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00043\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 5.3287e-04\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00043\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 4.9529e-04\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00043\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 4.6298e-04\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00043\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 4.8551e-04\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00043\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 5.2552e-04\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00043\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 5.8757e-04\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00043\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 5.3030e-04\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00043\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 4.5520e-04\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00043\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 4.4351e-04\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00043\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x221875586a0>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "decoded_arr = auto_encoder.predict(fin_array)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "a_array = fin_array.reshape(5552, 8)\r\n",
    "b_array = decoded_arr.reshape(5552, 8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# f = open(\"flag_1.txt\", 'w')\r\n",
    "num = np.zeros(shape = (5552, 8))\r\n",
    "flag_1 = 0\r\n",
    "flag_2 = 0\r\n",
    "flag_3 = 0\r\n",
    "flag_4 = 0\r\n",
    "flag_5 = 0\r\n",
    "for i in range(5552):\r\n",
    "    for j in range(8):\r\n",
    "        num[i][j] = abs(a_array[i][j] - b_array[i][j])\r\n",
    "        if (num[i][j] < 0.1):\r\n",
    "            flag_1 += 1\r\n",
    "            # f.write(\"{} {}\\n\".format(i, j))\r\n",
    "        elif (num[i][j] < 0.3):\r\n",
    "            flag_2 += 1\r\n",
    "        elif (num[i][j] < 0.5):\r\n",
    "            flag_3 += 1\r\n",
    "        elif (num[i][j] < 0.7):\r\n",
    "            flag_4 += 1\r\n",
    "        else:\r\n",
    "            flag_5 += 1\r\n",
    "#f.close()\r\n",
    "print(flag_1, flag_2, flag_3, flag_4, flag_5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "44188 219 5 2 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "np.savetxt('AE_abs_2.csv', num, delimiter=',')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d27cd36f75a1007aa809f85f0a98ba31dde81d89f2e1bdfebe9cb5cef9498e62"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}